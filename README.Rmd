---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-"
)
options(width = 99)
```

# campfin <img src="man/figures/logo.png" align="right" width="120" />

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/campfin)](https://cran.r-project.org/package=campfin)

## Overview

The `campfin` package was created to facilitate the work being done on the 
[The Accountability Project][tap], a tool created by 
[The Investigative Reporting Workshop][irw] in Washington, DC. The
Accountability Project curates, cleans, and indexes public data to give
journalists, researchers and others a simple way to search across otherwise
siloed records. 

The data focuses on people, organizations and locations. This
package was created specifically to help with state-level **camp**aign
**fin**ance data, although the tools included are useful in general database
exploration and normalization.

[tap]: https://www.publicaccountability.org/
[irw]: https://investigativereportingworkshop.org/
[fin]: https://en.wikipedia.org/wiki/Campaign_finance

## Installation

The package is not yet on [CRAN][cran] and must be installed from GitHub. As of
now, the package lives on the GitHub page of it's original developer.

```{r install, eval=TRUE, warning=FALSE, message=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("kiernann/campfin")
pacman::p_load(tidyverse, zipcode)
```

[cran]: https://cran.r-project.org/
[tidyverse]: https://www.tidyverse.org/

## Normalize

The package was originally built to normalize geographic data using the
`normal_*()` functions, which take the messy self-reported geographic data of a
contributor, vendor, candidate, or committee and return [normalized text][txt]
that is more searchable. They are largely wrappers around the 
[`stringr`][stringr] package, and can call other sub-functions to streamline
normalization.

* `normal_address()` takes a _street_ address and reduces inconsistencies.
* `normal_zip()` takes [ZIP Codes][zip] and aims to return a valid 5-digit code.
* `normal_state()` takes US states and returns a [2 digit abbreviation][abbs].
* `normal_city()` takes cities and reduces inconsistencies.

[txt]: https://en.wikipedia.org/wiki/Text_normalization
[stringr]: https://github.com/tidyverse/stringr
[zip]: https://en.wikipedia.org/wiki/ZIP_Code 
[abbs]: https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations

Please see the vignette on normalization for an example of how these functions
are used to fix a wide variety of string inconsistencies and make campaign 
finance data more consistent.

## Data

The campfin package contains a number of built in data frames and strings used
to help wrangle campaign finance data.

```{r data}
data(package = "campfin")$results[, "Item"]
```

The `/data-raw` directory contains the code used to create the objects.

### `zipcodes`

The `zipcodes` (plural) data frame is a normalized version of the `zipcode`
(singular) data frame from the [`zipcode`][zip] R package, which itself is a
version of the [CivicSpace US ZIP Code Database][civic]:

> This database was composed using ZIP code gazetteers from the US Census Bureau
from 1999 and 2000, augmented with additional ZIP code information The database
is believed to contain over 98% of the ZIP Codes in current use in the United
States. The remaining ZIP Codes absent from this database are entirely PO Box or
Firm ZIP codes added in the last five years, which are no longer published by
the Census Bureau, but in any event serve a very small minority of the
population (probably on the order of .1% or less). Although every attempt has
been made to filter them out, this data set may contain up to .5% false
positives, that is, ZIP codes that do not exist or are no longer in use but are
included due to erroneous data sources.

The included `valid_city` and `valid_zip` vectors are sorted, unique columns
from the `zipcodes` data frame (although `valid_city` is being updated to
include more common neighborhoods and census-designated places)

[zip]: https://cran.r-project.org/web/packages/zipcode/
[civic]: https://boutell.com/zipcodes/

```{r geo_df, collapse=TRUE, warning=FALSE, message=FALSE, error=FALSE}
# zipcode version
data("zipcode")
sample_n(zipcode, 5)
class(zipcode)

# campfin version
sample_n(zipcodes, 5)
class(zipcodes)
```

### `usps_*` and `valid_*`

The `usps_*` data frames were scraped from the official United States Postal
Service (USPS) 
[Postal Addressing Standards](https://pe.usps.com/text/pub28/28apc_002.htm). 
These data frames are designed to work with the abbreviation functionality of
`normal_address()` and `normal_city()` to replace common abbreviations with
their full equivalent.

`usps_city` is a curated subset of `usps_state`, whose full version appear at
least once in the `valid_city` vector from `zipcodes`. The `valid_state` and
`valid_name` vectors contain the columns from `usps_state` and include
territories not found in R's build in `state.abb` and `state.name` vectors.

```{r usps}
sample_n(usps_street, 5)
sample_n(usps_city, 5)
sample_n(usps_state, 5)
setdiff(valid_state, state.abb)
setdiff(valid_name, str_to_upper(state.name))
```

### Other

The `invalid_city` vector contains, appropriately, common invalid city names,
which can be passed to `normal_city()`.

```{r na_city}
sample(invalid_city, 5)
```

The `rx_zip` and `rx_state` character strings are useful regular expressions for
extracting geographic data from a single string address, data which can then be
passed to `normal_zip()` and `normal_state()`.

```{r print_rx, collapse=TRUE}
print(rx_zip)
print(rx_state)
```

```{r rx_strings, collapse=TRUE}
white_house <- "1600 Pennsylvania Ave NW, Washington, DC 20500-0003"
str_extract(white_house, pattern = rx_zip)
str_extract(white_house, pattern = rx_state)
```

The `vt_contribs` data frame contains example campaign contribution data from
a fictional election in Vermont. The data is used in the normalization vignette.

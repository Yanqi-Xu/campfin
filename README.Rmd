---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-"
)
```

# campfin <img src="man/figures/logo.png" align="right" width="120" />

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/campfin)](https://cran.r-project.org/package=campfin)

## Overview

The `campfin` package was created to facilitate the work being done by 
[The Accountability Project][01], a tool created by [The Investigative Reporting Workshop][02]. The
Accountability Project curates, cleans and indexes public data to give journalists, researchers and
others a simple way to search across otherwise siloed records. The data focuses on people,
organizations and locations. This package was created specifically to helo with state-level
**camp**aign **fin**ance data.

[01]: https://www.publicaccountability.org/ "tap"
[02]: https://investigativereportingworkshop.org/ "irw"

## Installation

The package is not on CRAN and must be installed from GitHub.

```{r install, eval=TRUE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("kiernann/campfin")
pacman::p_load(tidyverse, knitr, zipcode)
```

## Normalize

The most important functions are the in the `normal_*()` family. These functions take geographic
data and return [normalized text][03] that is more searchable. They are largely wrappers around
the [`stringr` package][07].

* `normal_zip()` takes [ZIP Codes][04] and returns a 5 digit character string
* `normal_state()` takes US states and returns a [2 digit abbreviation][05]
* `normal_address()` takes a _street_ address and reduces inconsistencies
* `normal_city()` takes cities and reduces inconsistencies (to help with [cluster and merging][06])

[03]: https://en.wikipedia.org/wiki/Text_normalization "text_normal"
[04]: https://en.wikipedia.org/wiki/ZIP_Code "zip_code"
[05]: https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations "state_abbs"
[06]: https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth "open_refine"
[07]: https://github.com/tidyverse/stringr "stringr"

In this example, we can see how the `normal_*()` function work with the built in data to turn 
messy data into a single normalized format.

```{r tribble, echo=FALSE}
vt <- tribble(
  ~address,             ~city,          ~state,    ~zip,
  "744 Cape Cod Rd.",      "Stowe, VT",    "VT",        "05672-5563",
  "EVERYWHERE",            "Morrisville",  "REQUESTED", "N/A",
  "149-church-st p-o-14",  "Burlington",   "Vermont",   "05401", 
  "51 depot      square",  "st johnsbury", "vt",        "5819",
  "XXXXXXX",               "UNKNOWN",      "DC",        "00000"
)
kable(vt, "markdown")
```

```{r normalize}
vt <- vt %>% mutate(
  address = normal_address(
    address = address,
    # expand street abbs
    add_abbs = usps_street,
    # remove invalid strings
    na = invalid_city,
    # remove single repeating chars
    na_rep = TRUE
  ),
  city = normal_city(
    city = city,
    # expand city abbs
    geo_abbs = usps_city,
    # remove state abbs
    st_abbs = c("VT"),
    # remove invalid cities
    na = invalid_city,
    na_rep = TRUE
  ),
  state = normal_state(
    state = state,
    abbreviate = TRUE,
    # remove all not in geo
    valid = valid_state
  ),
  zip = normal_zip(
    zip = zip,
    na = invalid_city,
    na_rep = TRUE
  )
)
```

```{r kable_normal, echo=FALSE}
vt %>% 
  map_df(str_replace_na) %>% 
  map_df(str_remove, "NA") %>% 
  kable("markdown")
```

## Data

The campfin package contains a number of built in data frames and strings used to help wrangle
campaign finance data.

```{r data}
cat(data(package = "campfin")$results[, "Item"], sep = "\n")
```

The `geo` [tibble][08] is a normalized version of the `zipcodes` data frame from the 
[`zipcodes`][09] R package, which itself is a version of the [CivicSpace US ZIP Code Database][10].

The `valid_city`, `valid_state`, and `valid_zip` are the unique, sorted columns of thr `geo` data
frame.

[08]: https://tibble.tidyverse.org/ "tibble"
[09]: https://cran.r-project.org/web/packages/zipcode/ "zip_pkg"
[10]: https://boutell.com/zipcodes/ "civic_space"

```{r geo_df, collapse=TRUE, warning=FALSE, message=FALSE, error=FALSE}
# zipcode version
data("zipcode")
sample_n(zipcode, 5)
class(zipcode)

# campfin version
sample_n(zipcodes, 5)
class(zipcodes)

# more US states than the built in state.abb
setdiff(valid_state, state.abb)
```

The `na_city` vector contains common invalid city names, which can be passed to `normal_city()`.

```{r na_city}
sample(invalid_city, 5)
```

The `usps_*` data frames can be used with `normal_*()` to
expand the [official USPS abbreviations](https://pe.usps.com/text/pub28/28apc_002.htm).

```{r usps}
sample_n(usps_city, 5)
sample_n(usps_state, 5)
sample_n(usps_street, 5)
```

The `rx_zip` and `rx_state` character strings are useful regular expressions for extracting data
from a single string address, which can then be passed to `normal_zip()` and `normal_state()`.

```{r print_rx, collapse=TRUE}
print(rx_zip)
print(rx_state)
```

```{r rx_strings, collapse=TRUE}
white_house <- "1600 Pennsylvania Ave NW, Washington, DC 20500-0003"
str_extract(white_house, pattern = rx_zip)
str_extract(white_house, pattern = rx_state)
```

Work is being done to incorperate regular expressions for addresses and city names, although
the immense possibility for variation makes these elements harder to generalize.

## Other

There are other functions designed to either facilitate normalization or help with data loading,
exploration, or cleaning. Many are just simple wrapper functions to speed up data wrangling.

```{r example_functions, collapse=TRUE}
abbrev_state(full = "VERMONT")
all_files_new("data/", glob = "*.rda")
read_csv(file = "x\n11/09/2016", col_types = readr::cols(x = col_date_usa()))
count_na(x = storms$ts_diameter)
expand_abbrev(x = "LK SHORE", abb = c("LK" = "LAKE"))
expand_state(abb = "VT")
flag_dupes(band_members, everything())
flag_na(band_members, everything())
glimpse_fun(data = band_members, fun = n_distinct)
is_abbrev(abb = "VT", full = "Vermont")
is_binary(x = c("Y", "N"))
is_even(x = 2012)
most_common(x = iris$Species, n = 1)
na_out(x = c("VT", "CA", "DC"), y = state.abb)
prop_in(x = c("VT", "CA", "DC"), y = state.abb)
prop_na(x = storms$hu_diameter)
prop_out(x = c("VT", "CA", "DC"), y = state.abb)
url_file_size("https://projects.fivethirtyeight.com/polls-page/senate_polls.csv", format = TRUE)
"DC" %out% state.abb
```

